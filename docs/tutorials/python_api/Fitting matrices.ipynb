{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97658521-39cc-4b66-b82a-e533a8d78901",
   "metadata": {},
   "source": [
    "# Fitting matrices\n",
    "\n",
    "**This notebook shows how you can fit your function to predict matrices for configurations**. We create the target matrices synthetically.\n",
    "\n",
    "Prerequisites\n",
    "-------------\n",
    "\n",
    "Before reading this notebook, **make sure you have read the [notebook on computing a matrix](<./Computing a matrix.ipynb>) and [the notebook on batching](./Batching.ipynb)**, which introduce the basic concepts of `graph2mat` that we are going to assume are already known. Also **we will use exactly the same setup as in the batching notebook**, with the only difference that we will compute add target matrices to each structure.\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "- Introduce the **addition of a target matrix** to a configuration.\n",
    "- **Introduce the metrics** that can be used as loss functions.\n",
    "- **Introduce the simplest training loop**.\n",
    "\n",
    "It is **specially useful if you are quite new to machine learning**, because it goes step by step. It also serves as a minimal example from which you can expand to create training flows different from the ones we propose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ffe9a-000b-4661-b7c4-b9bbfcc31575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# To load plotly templates for sisl visualization\n",
    "import sisl.viz\n",
    "\n",
    "from e3nn import o3\n",
    "\n",
    "from graph2mat import (\n",
    "    BasisConfiguration,\n",
    "    PointBasis,\n",
    "    BasisTableWithEdges,\n",
    "    MatrixDataProcessor,\n",
    ")\n",
    "from graph2mat.bindings.torch import TorchBasisMatrixDataset, TorchBasisMatrixData\n",
    "\n",
    "from graph2mat.bindings.e3nn import E3nnGraph2Mat\n",
    "\n",
    "from graph2mat.tools.viz import plot_basis_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af6f1b7-3385-4dbd-ae4a-8419dcb0bb16",
   "metadata": {},
   "source": [
    "Setting up the model\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db61cc2-6a99-4f0a-960b-a9be74af86fb",
   "metadata": {},
   "source": [
    "As usual, let's create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93af94-0193-41d2-aeeb-879801e15812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The basis\n",
    "point_1 = PointBasis(\"A\", R=2, basis=\"0e\", basis_convention=\"spherical\")\n",
    "point_2 = PointBasis(\"B\", R=5, basis=\"2x0e + 1o\", basis_convention=\"spherical\")\n",
    "\n",
    "basis = [point_1, point_2]\n",
    "\n",
    "# The basis table.\n",
    "table = BasisTableWithEdges(basis)\n",
    "\n",
    "# The data processor.\n",
    "processor = MatrixDataProcessor(\n",
    "    basis_table=table, symmetric_matrix=True, sub_point_matrix=False\n",
    ")\n",
    "\n",
    "positions = np.array([[0, 0, 0], [6.0, 0, 0], [12, 0, 0]])\n",
    "\n",
    "# The shape of the node features.\n",
    "node_feats_irreps = o3.Irreps(\"0e + 1o\")\n",
    "\n",
    "\n",
    "# The fake environment representation function that we will use\n",
    "# to compute node features.\n",
    "def get_environment_representation(data, irreps):\n",
    "    \"\"\"Function that mocks a true calculation of an environment representation.\n",
    "\n",
    "    Computes a random array and then ensures that the numbers obey our particular\n",
    "    system's symmetries.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    node_features = irreps.randn(data.num_nodes, -1)\n",
    "    # The point in the middle sees the same in -X and +X directions\n",
    "    # therefore its representation must be 0.\n",
    "    # In principle the +/- YZ are also equivalent, but let's say that there\n",
    "    # is something breaking the symmetry to make the numbers more interesting.\n",
    "    # Note that the spherical harmonics convention is YZX.\n",
    "    node_features[1, 3] = 0\n",
    "    # We make both A points have equivalent features except in the X direction,\n",
    "    # where the features are opposite\n",
    "    node_features[2::3, :3] = node_features[0::3, :3]\n",
    "    node_features[2::3, 3] = -node_features[0::3, 3]\n",
    "    return node_features\n",
    "\n",
    "\n",
    "# The matrix readout function\n",
    "model = E3nnGraph2Mat(\n",
    "    unique_basis=basis,\n",
    "    irreps=dict(node_feats_irreps=node_feats_irreps),\n",
    "    symmetric=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f63b226-d70e-4550-b073-232e2ef7b4f5",
   "metadata": {},
   "source": [
    "Including target matrices in the data\n",
    "-------------------------------------\n",
    "\n",
    "We will now create our data. The difference between this notebook and the previous notebooks is that **each configuration will have an associated matrix**, which is what we will try to fit.\n",
    "\n",
    "Usually, this matrix would be computed by the algorithm we are trying to substitute with ML (e.g. DFT for atomic systems) or experimental observations, but here we will just take random matrices.\n",
    "\n",
    "We create a function to compute random symmetric matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfec6f2-e126-42d9-9303-8a37209bd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_matrix(size):\n",
    "    \"\"\"Mocks the algorithm that provides the training matrices.\n",
    "\n",
    "    It just computes a random matrix\n",
    "    \"\"\"\n",
    "    matrix = np.random.random((size, size)) * 2 - 1\n",
    "    matrix += matrix.T\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69bf9b0-3c6a-4cc2-b4cf-2d35055e71a9",
   "metadata": {},
   "source": [
    "And then initialize the configurations as we have done in the previous notebooks, except that in this case we use the `matrix` argument to pass the matrix associated with the configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22dfc0-c3f9-4ee5-9fdf-cae85e6e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.array([[0, 0, 0], [6.0, 0, 0], [12, 0, 0]])\n",
    "\n",
    "config1 = BasisConfiguration(\n",
    "    point_types=[\"A\", \"B\", \"A\"],\n",
    "    positions=positions,\n",
    "    basis=basis,\n",
    "    cell=np.eye(3) * 100,\n",
    "    pbc=(False, False, False),\n",
    "    matrix=true_matrix(size=7),\n",
    ")\n",
    "\n",
    "config2 = BasisConfiguration(\n",
    "    point_types=[\"B\", \"A\", \"B\"],\n",
    "    positions=positions,\n",
    "    basis=basis,\n",
    "    cell=np.eye(3) * 100,\n",
    "    pbc=(False, False, False),\n",
    "    matrix=true_matrix(size=11),\n",
    ")\n",
    "\n",
    "configs = [config1, config2]\n",
    "\n",
    "# Create the dataset\n",
    "dataset = TorchBasisMatrixDataset(configs, data_processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069038ce-873f-4577-88af-6e89f723689e",
   "metadata": {},
   "source": [
    "We can take one example from the dataset and check that it now has `point_labels` and `edge_labels`, which contain the values of the matrix organized in the same way that are returned by `Graph2Mat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85607363-ba18-4207-bd09-bef25ced2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_example = dataset[0]\n",
    "data_example.point_labels, data_example.edge_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e3cd3-8262-4387-81fe-f2325d462123",
   "metadata": {},
   "source": [
    "During training, we will compare these to the output of `Graph2Mat`.\n",
    "\n",
    "We can also plot the target matrices from the data example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92e192-4b9b-4b3f-b359-a6f56096acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrices(data, predictions=None, title=\"\", show=True):\n",
    "    \"\"\"Helper function to plot (possibly batched) matrices\"\"\"\n",
    "\n",
    "    matrices = processor.matrix_from_data(data, predictions=predictions)\n",
    "\n",
    "    if not isinstance(matrices, (tuple, list)):\n",
    "        matrices = (matrices,)\n",
    "\n",
    "    for i, (config, matrix) in enumerate(zip(configs, matrices)):\n",
    "        if show is True or show == i:\n",
    "            plot_basis_matrix(\n",
    "                matrix,\n",
    "                config,\n",
    "                point_lines={\"color\": \"black\"},\n",
    "                basis_lines={\"color\": \"blue\"},\n",
    "                colorscale=\"temps\",\n",
    "                text=\".2f\",\n",
    "                basis_labels=True,\n",
    "            ).update_layout(title=f\"{title} [{i}]\").show()\n",
    "\n",
    "\n",
    "plot_matrices(data_example, title=\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d352232-09b1-4138-bccd-c98b32762781",
   "metadata": {},
   "source": [
    "The simplest training loop\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57087fa4-1dba-452e-ba4e-b0cae54edb99",
   "metadata": {},
   "source": [
    "Below we just create a simple `pytorch` training loop that:\n",
    "\n",
    "1. Uses the model to **compute predictions** for the matrix\n",
    "2. **Computes the loss** (error).\n",
    "3. Computes the gradients and **updates the model parameters**.\n",
    "4. **Goes back** to 1.\n",
    "\n",
    "While doing so we store the errors at each step so that we can plot their evolution later.\n",
    "\n",
    "There is just one last thing that we need to introduce: `graph2mat`'s metrics. The `metrics` module contains several functions that compare matrices in different ways. They can be used as loss functions. In this case, we will use `elementwise_mse`, which just computes the [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) of all the matrix elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c1eb06-2e2f-4ca5-b298-25064bf8ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data loader\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "# Number of training steps\n",
    "n_steps = 4000\n",
    "# Initialize an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Initialize arrays to store errors\n",
    "losses = np.zeros(n_steps)\n",
    "node_rmse = np.zeros(n_steps)\n",
    "edge_rmse = np.zeros(n_steps)\n",
    "\n",
    "# The loss function, which we get from graph2mat's metrics functions\n",
    "from graph2mat import metrics\n",
    "\n",
    "loss_fn = metrics.elementwise_mse\n",
    "\n",
    "# Loop\n",
    "for i in range(n_steps):\n",
    "    for data in loader:\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get the node feats. Since this function is not learnable, it could be\n",
    "        # outside the loop, but we keep it here to show how things could work\n",
    "        # with a learnable environment representation.\n",
    "        node_feats = get_environment_representation(data, node_feats_irreps)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        step_predictions = model(data, node_feats=node_feats)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss, info = loss_fn(\n",
    "            nodes_pred=step_predictions[0],\n",
    "            nodes_ref=data.point_labels,\n",
    "            edges_pred=step_predictions[1],\n",
    "            edges_ref=data.edge_labels,\n",
    "        )\n",
    "\n",
    "        # Store errors\n",
    "        losses[i] = loss\n",
    "        node_rmse[i] = info[\"node_rmse\"]\n",
    "        edge_rmse[i] = info[\"edge_rmse\"]\n",
    "\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409b16e-ed88-407f-b867-53a82ec861bc",
   "metadata": {},
   "source": [
    "Checking results\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c4b20-84d7-49bc-9895-7b5fd1ad072b",
   "metadata": {},
   "source": [
    "After training, we store all the errors in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8e695-de12-4f3b-aac3-06bca144ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.array([losses, node_rmse, edge_rmse]).T,\n",
    "    columns=[\"loss\", \"node_rmse\", \"edge_rmse\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a0322-26fe-4431-a5aa-89e3df240701",
   "metadata": {},
   "source": [
    "And plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c992cf-fbfc-4eb6-9208-ebdb60cd3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(backend=\"plotly\").update_layout(\n",
    "    yaxis_type=\"log\", yaxis_showgrid=True, xaxis_showgrid=True\n",
    ").update_layout(\n",
    "    yaxis_title=\"Value\",\n",
    "    xaxis_title=\"Training step\",\n",
    "    title=\"Error evolution during training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92157c-51ec-4b0e-b45d-5ccedaa54d65",
   "metadata": {},
   "source": [
    "The model has learned something, but still the errors are quite high.\n",
    "\n",
    "We can plot the first target matrix and the corresponding prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60b52d-e64c-4b73-85ec-7690fa59deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrices(data, title=f\"Target matrix\", show=0)\n",
    "plot_matrices(\n",
    "    data,\n",
    "    predictions={\n",
    "        \"node_labels\": step_predictions[0],\n",
    "        \"edge_labels\": step_predictions[1],\n",
    "    },\n",
    "    title=f\"Prediction after {n_steps} training steps\",\n",
    "    show=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375352d-adc8-458e-ae07-8fd19c11c72f",
   "metadata": {},
   "source": [
    "As you can see, the matrices are very different. That is, the model has no idea how to predict the matrices!\n",
    "\n",
    "This could be shocking considering that it has only been tasked with fitting 2 matrices, a super simple problem that any model would overfit without any trouble. Well, you must take into account two things:\n",
    "\n",
    "- **The target matrix is random**, while **the model is designed to learn equivariant matrices!**. All operations are equivariant and therefore result into an equivariant predicted matrix. For example, symmetry determines that the scalar element for node blocks for points 0 and 2 (at the top-left and bottom-right corner of the matrix) must be exactly the same because the point are equivalent. The random matrix does not satisfy this condition so it is impossible to fit.\n",
    "\n",
    "- **The model is limited by the input node features**, which only contain one scalar and one vector. The combination possibilities are very small. If you increase the node feats irreps to `0e + 2x1o` (i.e. add one extra vector) and modify the `get_environment_representation` to still satisfy symmetries you should see some elements that have no symmetry problems (e.g. the 4 scalar elements at the top-left corner of node block for point 1) get very close to the target matrix.\n",
    "\n",
    "We could work very hard to make our fake environment and true matrix computing functions equivariant to see the model fit perfectly, but you will see this in other real-life examples in the tutorials. Also **it is nice to see how a random matrix can't be fitted by an equivariant model to understand the power of equivariant design**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1020c-9d8c-484c-b8aa-5bd211b9a9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
